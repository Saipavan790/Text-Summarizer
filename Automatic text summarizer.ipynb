{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c3c193",
   "metadata": {},
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b7110",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "OSError: [WinError 123] The filename, directory name, or volume label syntax is incorrect: '\"c:'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66027a19",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5a505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r\"C:\\Users\\Sai Pavan Vulasi\\Desktop\\text_dataset\\news_summary.csv\",encoding='iso-8859-1',usecols=['headlines','text'])\n",
    "df2 = pd.read_csv(r\"C:\\Users\\Sai Pavan Vulasi\\Desktop\\text_dataset\\news_summary_more.csv\",encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "413d6ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1  Malaika slams user who trolled her for 'divorc...   \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...   \n",
       "4  Hotel staff to get training to spot signs of s...   \n",
       "\n",
       "                                                text  \n",
       "0  The Administration of Union Territory Daman an...  \n",
       "1  Malaika Arora slammed an Instagram user who tr...  \n",
       "2  The Indira Gandhi Institute of Medical Science...  \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
       "4  Hotels in Maharashtra will train their staff t...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44443515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4514, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b1b126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdfbacd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98401, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efd6c87",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3815a7",
   "metadata": {},
   "source": [
    "The aim of the preprocessing step is to reduce the\n",
    "dimensionality of the representation space, and it normally includes: (i) stop-word\n",
    "elimination – common words with no semantics and which do not aggregate relevant\n",
    "information to the task (e.g., “the”, “a”) are eliminated;; (ii) case folding: consists of\n",
    "converting all the characters to the same kind of letter case - either upper case or\n",
    "lower case; (iii) stemming: syntactically-similar words, such as plurals, verbal\n",
    "variations, etc. are considered similar; the purpose of this procedure is to obtain the\n",
    "stem or radix of each word, which emphasize its semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ae0028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1  Malaika slams user who trolled her for 'divorc...   \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...   \n",
       "4  Hotel staff to get training to spot signs of s...   \n",
       "\n",
       "                                                text  \n",
       "0  The Administration of Union Territory Daman an...  \n",
       "1  Malaika Arora slammed an Instagram user who tr...  \n",
       "2  The Indira Gandhi Institute of Medical Science...  \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
       "4  Hotels in Maharashtra will train their staff t...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate two dataframes to get total data\n",
    "df = pd.concat([df1,df2],axis=0,ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d71d0170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102915, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8324b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates and null values\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1c8949d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100266, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b4c656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size : 100266\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset size : {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13cf5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantext(text):\n",
    "    text = str(text)\n",
    "    text=text.split()\n",
    "    words=[]\n",
    "    for t in text:\n",
    "        if t.isalpha():\n",
    "            words.append(t)\n",
    "    text=\" \".join(words)\n",
    "    text=text.lower()\n",
    "    text=re.sub(r\"what's\",\"what is \",text)\n",
    "    text=re.sub(r\"it's\",\"it is \",text)\n",
    "    text=re.sub(r\"\\'ve\",\" have \",text)\n",
    "    text=re.sub(r\"i'm\",\"i am \",text)\n",
    "    text=re.sub(r\"\\'re\",\" are \",text)\n",
    "    text=re.sub(r\"n't\",\" not \",text)\n",
    "    text=re.sub(r\"\\'d\",\" would \",text)\n",
    "    text=re.sub(r\"\\'s\",\"s\",text)\n",
    "    text=re.sub(r\"\\'ll\",\" will \",text)\n",
    "    text=re.sub(r\"can't\",\" cannot \",text)\n",
    "    text=re.sub(r\" e g \",\" eg \",text)\n",
    "    text=re.sub(r\"e-mail\",\"email\",text)\n",
    "    text=re.sub(r\"9\\\\/11\",\" 911 \",text)\n",
    "    text=re.sub(r\" u.s\",\" american \",text)\n",
    "    text=re.sub(r\" u.n\",\" united nations \",text)\n",
    "    text=re.sub(r\"\\n\",\" \",text)\n",
    "    text=re.sub(r\":\",\" \",text)\n",
    "    text=re.sub(r\"-\",\" \",text)\n",
    "    text=re.sub(r\"\\_\",\" \",text)\n",
    "    text=re.sub(r\"\\d+\",\" \",text)\n",
    "    text=re.sub(r\"[$#@%&*!~?%{}()]\",\" \",text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d96dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: cleantext(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be8f477a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daman diu revokes mandatory rakshabandhan in o...</td>\n",
       "      <td>the administration of union territory daman an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malaika slams user who trolled her for rich</td>\n",
       "      <td>malaika arora slammed an instagram user who tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>now corrected to in form</td>\n",
       "      <td>the indira gandhi institute of medical science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaj aapne pakad let man dujana before being ki...</td>\n",
       "      <td>kashmir commander abu who was killed by securi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hotel staff to get training to spot signs of s...</td>\n",
       "      <td>hotels in maharashtra will train their staff t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  daman diu revokes mandatory rakshabandhan in o...   \n",
       "1        malaika slams user who trolled her for rich   \n",
       "2                           now corrected to in form   \n",
       "3  aaj aapne pakad let man dujana before being ki...   \n",
       "4  hotel staff to get training to spot signs of s...   \n",
       "\n",
       "                                                text  \n",
       "0  the administration of union territory daman an...  \n",
       "1  malaika arora slammed an instagram user who tr...  \n",
       "2  the indira gandhi institute of medical science...  \n",
       "3  kashmir commander abu who was killed by securi...  \n",
       "4  hotels in maharashtra will train their staff t...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "928db258",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['text'] = df['text']\n",
    "data['summary'] = df['headlines']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c8330",
   "metadata": {},
   "source": [
    "Remember to add the START and END special tokens at the beginning and end of the summary. Here, I have chosen sostok and eostok as START and END tokens. The beginning-of-sentence token serves as an instruction to the decoder to start decoding (it needs a very first state to predict what the next first token is). The end-of-sentence token is an instruction for the decoding algorithm to stop generating more tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177724a5",
   "metadata": {},
   "source": [
    "## Understanding distribution of sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c09d22",
   "metadata": {},
   "source": [
    "Here, we will analyze the length of the reviews and the summary to get an overall idea about the distribution of length of the text. This will help us fix the maximum length of the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "230b60d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999900265294317\n"
     ]
    }
   ],
   "source": [
    "text_count = 0\n",
    "for text in data['text']:\n",
    "    if len(text.split())<60:\n",
    "        text_count += 1\n",
    "print(text_count/len(data['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3de49ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999601061177269\n"
     ]
    }
   ],
   "source": [
    "summary_count = 0\n",
    "for summary in data['summary']:\n",
    "    if len(summary.split())<15:\n",
    "        summary_count+=1\n",
    "print(summary_count/len(data['summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3126cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYJUlEQVR4nO3df5BlZZ3f8fdH8AdBERC3ZWdwh9UpLVYiPybCRrPbgsIIRkyVGi02jBQlSYm1WmFVsJJiVyWBPxRl1zVhZZbBVZFCUaK4OAG63FQCAqIgoMXIjpmZAkYdfji4aEa/+eM+rdee7p7uO933F+9X1a2+5zk/7nNPn+7PPc957nNSVUiSntqeNugKSJIGzzCQJBkGkiTDQJKEYSBJwjCQJGEYSJIwDEZOks1JXjMs25E0HgwDSZpDkn0HXYd+MQxGSJJPAy8E/keSnUnel+T4JP87yaNJvpNksi37L5P8OMlhbfrlSR5J8tLZtjOo96Txl+T9SbYl+WmS7yc5MckVST7ctcxkkq1d05uTvDfJXUmeSHJ5kokkX2vb+Z9JDmrLrkpSSc5MsqUd5/8hyb9o6z+a5K+6tv2iJDcl+Un7G/lMkgNnvPb7k9wFPNHq8YUZ7+nSJB9fzv3Wd1XlY4QewGbgNe35CuAnwCl0gv21bfr5bf6FwE3AfsDdwLtm244PH8v1AF4CbAF+t02vAl4EXAF8uGu5SWBr1/Rm4BZgoh3n24FvAUcDz2rH9QVd2yzgv7V5JwFPAl8Cfqdr/T9uy7+4/a08E3g+8A3gYzNe+9vAYe1v51DgCeDANn/ftr1jB71/l/LhmcFo+xPg+qq6vqp+VVUbgdvphAPAnwPPBb4JbAM+MZBa6qnsl3T+6R6R5OlVtbmqfrDAdf+yqh6uqm3APwC3VtWdVfUkcC2dYOj2oap6sqq+Tuef9+eqanvX+kcDVNWmqtpYVT+vqh8BHwX+eMa2Lq2qLVX1T1X1IJ3AeHObtxb4cVXdsag9MeQMg9H2e8Cb22nwo0keBV5F55MMVfX/6HwCexnwkWofa6R+qapNwHvofDDZnuSqJL+7wNUf7nr+T7NMP7uX5Vtz01Wt6epx4O+AQ2Zsa8uM6Q10PnzRfn56ge9hZBgGo6f7H/oW4NNVdWDXY/+qugggyQrgAuBvgY8keeYc25GWTVV9tqpeRefDSwEX0/nk/s+6FntBH6v0X1o9jqyqA+j8c8+MZWb+fXwJ+OdJXga8HvjMcley3wyD0fMw8Pvt+d8B/zrJyUn2SfKsdiFuZZLQOSu4HDgLeBD40BzbkZZFkpckOaF9EHmSzif0X9Fpkz8lycFJXkDn7KFfngPsBB5rH5jeu6cVWtPUNcBngW9W1f9d3ir2n2Ewev4r8J9ak9C/BU4DPgD8iM6Zwnvp/F7/lM7Fs//cmofOBM5M8q9mbifJn/X3Legp5JnARcCPgYfoHJPn02lm+Q6di7VfBz7fxzr9BXAM8BjwVeCLC1xvA3AkY9hEBBCbkSVpz5K8EPge8IKqenzQ9VlqnhlI0h4keRrwH4GrxjEIoNNfVpI0hyT707nG9kM63UrHks1EkiSbiSRJI9xMdMghh9SqVat+Pf3EE0+w//77D65CPbDO/TFXne+4444fV9XzB1Clnsw85ofdKB4r00a57tDjMT/o8TB6fRx77LHV7eabb65RY537Y646A7fXEBzLC33MPOaH3SgeK9NGue5VvR3zNhNJkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJIkRHo5Co23VeV9d9DqbLzp1GWqiceJx1TvPDCRJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSWGAYJNmc5O4k305yeys7OMnGJPe3nwe18iS5NMmmJHclOaZrO+va8vcnWddVfmzb/qa2bpb6jUqS5raYM4NXV9VRVbWmTZ8H3FhVq4Eb2zTA64DV7XE28EnohAdwAXAc8ArggukAacu8o2u9tT2/I0nSou1NM9FpwIb2fAPwxq7yK6vjFuDAJIcCJwMbq2pHVT0CbATWtnkHVNUtVVXAlV3bkiT1wULvZ1DA15MU8N+r6jJgoqoebPMfAiba8xXAlq51t7ay+cq3zlK+myRn0znbYGJigqmpqV/P27lz529Nj4Kncp3PPXLXotfp9XVHcT9L/bbQMHhVVW1L8jvAxiTf655ZVdWCYlm1ELoMYM2aNTU5OfnreVNTU3RPj4Kncp3f3stNSE7v7XVHcT9L/bagZqKq2tZ+bgeupdPm/3Br4qH93N4W3wYc1rX6ylY2X/nKWcolSX2yxzBIsn+S50w/B04CvgtcB0z3CFoHfLk9vw44o/UqOh54rDUn3QCclOSgduH4JOCGNu/xJMe3XkRndG1LktQHC2kmmgCubb099wU+W1V/n+Q24OokZwE/BN7Slr8eOAXYBPwMOBOgqnYk+RBwW1vug1W1oz1/J3AFsB/wtfaQJPXJHsOgqh4AXj5L+U+AE2cpL+CcOba1Hlg/S/ntwMsWUF9J0jLwG8iSJMNAkmQYSJIwDCRJGAbSnJLsk+TOJF9p04cnubUNqPj5JM9o5c9s05va/FVd2zi/lX8/ycld5Wtb2aYk5+324lKfGQbS3N4N3Nc1fTFwSVW9GHgEOKuVnwU80sovacuR5AjgrcAf0Bl88a9bwOwDfILOoI5HAG9ry0oDYxhIs0iyEjgV+FSbDnACcE1bZObgjNODNl4DnNiWPw24qqp+XlX/SOe7N69oj01V9UBV/QK4qi0rDcxCxyaSnmo+BrwPeE6bfh7waFVNj7DXPaDirwdhrKpdSR5ry68AbunaZvc6MwdtPG62Ssw3OOOwG8QAgUs1AOKoD27YS/0NA2mGJK8HtlfVHUkmB1mX+QZnHHaDGCBwqQZAHPXBDXupv2Eg7e6VwBuSnAI8CzgA+Dide3Ps284OugdUnB6EcWuSfYHnAj9h7sEZmadcGgivGUgzVNX5VbWyqlbRuQB8U1WdDtwMvKktNnNwxulBG9/Ulq9W/tbW2+hwOnfx+yad8blWt95Jz2ivcV0f3po0J88MpIV7P3BVkg8DdwKXt/LLgU8n2QTsoPPPnaq6J8nVwL3ALuCcqvolQJJ30RnJdx9gfVXd09d3Is1gGEjzqKopYKo9f4BOT6CZyzwJvHmO9S8ELpyl/Ho6I/xKQ8FmIkmSYSBJMgwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJYhFhkGSfJHcm+UqbPjzJrUk2Jfl8u30f7RZ/n2/ltyZZ1bWN81v595Oc3FW+tpVtSnLeEr4/SdICLObM4N3AfV3TFwOXVNWLgUeAs1r5WcAjrfySthxJjqBzO8A/ANYCf90CZh/gE8DrgCOAt7VlJUl9sqAwSLISOBX4VJsOcAJwTVtkA/DG9vy0Nk2bf2Jb/jTgqqr6eVX9I7CJzi0EXwFsqqoHquoXwFVtWUlSnyz0HsgfA94HPKdNPw94tKp2temtwIr2fAWwBaCqdiV5rC2/Arila5vd62yZUX7cbJVIcjZwNsDExARTU1O/nrdz587fmh4FT+U6n3vkrj0vNEOvrzuK+1nqtz2GQZLXA9ur6o4kk8teo3lU1WXAZQBr1qypycnfVGdqaoru6VHwVK7z28/76qLX2Xx6b687ivtZ6reFnBm8EnhDklOAZwEHAB8HDkyybzs7WAlsa8tvAw4DtibZF3gu8JOu8mnd68xVLknqgz1eM6iq86tqZVWtonMB+KaqOh24GXhTW2wd8OX2/Lo2TZt/U1VVK39r6210OLAa+CZwG7C69U56RnuN65bk3UmSFmSh1wxm837gqiQfBu4ELm/llwOfTrIJ2EHnnztVdU+Sq4F7gV3AOVX1S4Ak7wJuAPYB1lfVPXtRL0nSIi0qDKpqCphqzx+g0xNo5jJPAm+eY/0LgQtnKb8euH4xdZEkLR2/gSxJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJLYuy+dSQCs6mGcIUnDxTMDSZJhIEkyDCRJGAbSbpI8K8k3k3wnyT1J/qKVe99vjS3DQNrdz4ETqurlwFHA2iTH432/NcYMA2mG6tjZJp/eHoX3/dYYs2upNIv26f0O4MV0PsX/gCG77/ewG8S9p5fq3tqjft/sXupvGEizaDdeOirJgcC1wEsHVI857/s97AZx7+mlurf2qN83u5f620wkzaOqHqVzi9c/pN33u82a7b7fLPC+3/PdD1waCMNAmiHJ89sZAUn2A14L3If3/dYYs5lI2t2hwIZ23eBpwNVV9ZUk9+J9vzWmDANphqq6Czh6lnLv+62xZTORJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJJYQBh41ydJGn8LOTPwrk+SNOb2GAbe9UmSxt+CBqobhbs+jeKdicalzr3cXaoXve6rUdzPUr8tKAxG4a5Po3hnonGpcy93l+rFbHekWohR3M9Svy2qN5F3fZKk8bSQ3kTe9UmSxtxCmom865Mkjbk9hoF3fZKk8ec3kCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIO0myWFJbk5yb5J7kry7lR+cZGOS+9vPg1p5klyaZFOSu5Ic07WtdW35+5Os6yo/NsndbZ1Lk6T/71T6DcNA2t0u4NyqOgI4HjgnyRHAecCNVbUauLFNA7wOWN0eZwOfhE54ABcAx9G5RewF0wHSlnlH13pr+/C+pDkZBtIMVfVgVX2rPf8pcB+wAjgN2NAW2wC8sT0/DbiyOm4BDkxyKHAysLGqdlTVI8BGYG2bd0BV3VJVBVzZtS1pIPYddAWkYZZkFXA0cCswUVUPtlkPARPt+QpgS9dqW1vZfOVbZymf7fXPpnO2wcTEBFNTU72/mT7buXNn3+t77pG7Fr3ObHUcRN2XUi/1NwykOSR5NvAF4D1V9Xh3s35VVZJa7jpU1WXAZQBr1qypycnJ5X7JJTM1NUW/6/v287666HU2nz65W9kg6r6Ueqm/zUTSLJI8nU4QfKaqvtiKH25NPLSf21v5NuCwrtVXtrL5ylfOUi4NjGEgzdB69lwO3FdVH+2adR0w3SNoHfDlrvIzWq+i44HHWnPSDcBJSQ5qF45PAm5o8x5Pcnx7rTO6tiUNhM1E0u5eCfw74O4k325lHwAuAq5OchbwQ+Atbd71wCnAJuBnwJkAVbUjyYeA29pyH6yqHe35O4ErgP2Ar7WHNDCGgTRDVf0vYK5+/yfOsnwB58yxrfXA+lnKbwdethfVlJaUzUSSJMNAkmQzkaQhtKqHLqLaO3s8M3CcFkkafwtpJnKcFkkac3sMA8dpkaTxt6gLyIMep0WStDwWfAF5GMZpmW/QrlEcWGpc6tzL4GC96HVfjeJ+lvptQWEw3zgtVfXgIsZpmZxRPsUixmmZb9CuURxYalzq3MvgYL2YbUCxhRjF/Sz120J6EzlOiySNuYWcGThOiySNuT2GgeO0SNL4czgKSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQWcXMbSRpHq2a5H8e5R+6a9z4dmy86dTmrNBCeGUiSDANJkmEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIM0qyfok25N8t6vs4CQbk9zffh7UypPk0iSbktyV5Jiudda15e9Psq6r/Ngkd7d1Lk2S/r5D6bcZBtLsrgDWzig7D7ixqlYDN7ZpgNcBq9vjbOCT0AkP4ALgOOAVwAXTAdKWeUfXejNfS+orw0CaRVV9A9gxo/g0YEN7vgF4Y1f5ldVxC3BgkkOBk4GNVbWjqh4BNgJr27wDquqWqirgyq5tSQPhqKXSwk1U1YPt+UPARHu+AtjStdzWVjZf+dZZyneT5Gw6ZxtMTEwwNTW1d++gj3bu3MnU1BR3b3ts0euee+QyVGgRJvbrjFw6l2H/PUzv+8UwDKQeVFUlqT68zmXAZQBr1qypycnJ5X7JJTM1NcXk5OS8Q0EPq3OP3MVH7p773+Pm0yf7V5keTO/7xbCZSFq4h1sTD+3n9la+DTisa7mVrWy+8pWzlEsDYxhIC3cdMN0jaB3w5a7yM1qvouOBx1pz0g3ASUkOaheOTwJuaPMeT3J860V0Rte2pIHYYxjYxU5PRUk+B/wf4CVJtiY5C7gIeG2S+4HXtGmA64EHgE3A3wDvBKiqHcCHgNva44OtjLbMp9o6PwC+1o/3Jc1lIdcMrgD+ik6Ph2nTXewuSnJem34/v93F7jg63eeO6+pitwYo4I4k17UeFtNd7G6l80e1Fv8wNGBV9bY5Zp04y7IFnDPHdtYD62cpvx142d7UUVpKezwzsIudJI2/XnsT9b2LHczfza6XrlSDNi51nq8L3lLqdV+N4n6W+m2vu5b2q4tde605u9n10pVq0Malzv3qOthrd75R3M9Sv/Xam8gudpI0RnoNA7vYSdIY2WMzUetiNwkckmQrnV5BFwFXt+52PwTe0ha/HjiFTne5nwFnQqeLXZLpLnawexe7K4D96PQisieRJPXZHsPALnaSNP78BrIkyTCQJBkGkiQMA0kS3s9AkhZtVQ9ftNx80anLUJOl45mBJMkwkCQZBpIkDANJEl5AlrQIi7lweu6Ru/o2oq32nmcGkiTDQJJkGEiS8JqBZthTm7DtwNJ48sxAkmQYSJJsJtII6WU8GIAr1u6/xDWRxo9nBpIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJDFEYJFmb5PtJNiU5b9D1kZabx7yGyVCEQZJ9gE8ArwOOAN6W5IjB1kpaPh7zGjbDMoT1K4BNVfUAQJKrgNOAewdaqxHW63DP6puBH/MeI/3V6/7efNGpS1yT2Q1LGKwAtnRNbwWOm7lQkrOBs9vkziTf75p9CPDjZavh8hi5Ov/pCNb51RfPWeff63dduizFMT/URvFYmTZMdc/FPa226GN+WMJgQarqMuCy2eYlub2q1vS5SnvFOvfHKNZ52nzH/LAb5f0+ynWH3uo/FNcMgG3AYV3TK1uZNK485jVUhiUMbgNWJzk8yTOAtwLXDbhO0nLymNdQGYpmoqraleRdwA3APsD6qrpnkZsZxVNp69wfQ1fnJTrmh93Q7fdFGOW6Qw/1T1UtR0UkSSNkWJqJJEkDZBhIkkY/DEbhK/1JDktyc5J7k9yT5N2t/OAkG5Pc334eNOi6zpRknyR3JvlKmz48ya1tf3++XfwcGkkOTHJNku8luS/JH47Cfh43STYnuTvJt5PcPuj6zCfJ+iTbk3y3q2xkjpk56v/nSba1/f/tJKfsaTsjHQYj9JX+XcC5VXUEcDxwTqvnecCNVbUauLFND5t3A/d1TV8MXFJVLwYeAc4aSK3m9nHg76vqpcDL6dR9FPbzOHp1VR01Av31rwDWzigbpWPmCnavP3T+To9qj+v3tJGRDgO6vtJfVb8Apr/SP1Sq6sGq+lZ7/lM6/6BW0KnrhrbYBuCNA6ngHJKsBE4FPtWmA5wAXNMWGao6J3ku8EfA5QBV9YuqepQh388arKr6BrBjRvHIHDNz1H/RRj0MZvtK/4oB1WVBkqwCjgZuBSaq6sE26yFgYlD1msPHgPcBv2rTzwMerapdbXrY9vfhwI+Av21NW59Ksj/Dv5/HUQFfT3JHG1Jj1IzDMfOuJHe1ZqQ9NnONehiMlCTPBr4AvKeqHu+eV50+vkPTzzfJ64HtVXXHoOuyCPsCxwCfrKqjgSeYcXo/bPt5jL2qqo6h04R7TpI/GnSFejWix8wngRcBRwEPAh/Z0wqjHgYj85X+JE+nEwSfqaovtuKHkxza5h8KbB9U/WbxSuANSTbTaX47gU57/IFJpr+sOGz7eyuwtapubdPX0AmHYd7PY6mqtrWf24Fr6TTpjpKRPmaq6uGq+mVV/Qr4Gxaw/0c9DEbiK/2trf1y4L6q+mjXrOuAde35OuDL/a7bXKrq/KpaWVWr6OzXm6rqdOBm4E1tsWGr80PAliQvaUUn0hkSemj38zhKsn+S50w/B04Cvjv/WkNnpI+Z6SBr/g0L2P8j/w3k1mXqY/zmK/0XDrZGu0vyKuAfgLv5Tfv7B+hcN7gaeCHwQ+AtVbXXF4KWWpJJ4M+q6vVJfp/OmcLBwJ3An1TVzwdYvd+S5Cg6F7yfATwAnEnnQ8/Q7+dx0Y6Ra9vkvsBnh/HvclqSzwGTdIZ9fhi4APgSI3LMzFH/STpNRAVsBv591zWQ2bcz6mEgSdp7o95MJElaAoaBJMkwkCQZBpIkDANJEoaBJAnDQJIE/H830tjfPRzXkgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# get number of words in text and summary\n",
    "\n",
    "for i in data['text']:\n",
    "    text_word_count.append(len(i.split()))\n",
    "    \n",
    "for i in data['summary']:\n",
    "    summary_word_count.append(len(str(i).split()))\n",
    "    \n",
    "length = pd.DataFrame()\n",
    "length['text'] = pd.Series(text_word_count)\n",
    "length['summary'] = pd.Series(summary_word_count)\n",
    "\n",
    "length.hist(bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74bd91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=60\n",
    "max_summary_len=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7de50c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text =np.array(data['text'])\n",
    "summary=np.array(data['summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(text)):\n",
    "    if(len(str(summary[i]).split())<=max_summary_len and len(text[i].split())<=max_text_len):\n",
    "        short_text.append(text[i])\n",
    "        short_summary.append(summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfdf4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e5ed2",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8187055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96521441",
   "metadata": {},
   "source": [
    "## Tokenize: text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28735145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26da2c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 56.57998805546139\n",
      "Total Coverage of rare words: 1.1902033035582427\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77112b0",
   "metadata": {},
   "source": [
    "## Padding: pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a2cf8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08fc31c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26901"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e86bc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63703ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 55.537201701050854\n",
      "Total Coverage of rare words: 2.6054205341817265\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c85184cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac81b365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12652"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "622e86af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 60)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 60, 200)      5380200     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 60, 300),    601200      ['embedding[0][0]']              \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 60, 300),    721200      ['lstm[0][0]']                   \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 200)    2530400     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 60, 300),    721200      ['lstm_1[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 300),  601200      ['embedding_1[0][0]',            \n",
      "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 12652)  3808252    ['lstm_3[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,363,652\n",
      "Trainable params: 14,363,652\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.layers import Embedding,LSTM,Input,TimeDistributed,Dense\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=200\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a53b8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10cba72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d0a8bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 42/705 [>.............................] - ETA: 43:34 - loss: 5.3602"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sai Pavan Vulasi\\Desktop\\text_dataset\\Automatic text summarizer.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sai%20Pavan%20Vulasi/Desktop/text_dataset/Automatic%20text%20summarizer.ipynb#ch0000043?line=0'>1</a>\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit([x_tr,y_tr[:,:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]], y_tr\u001b[39m.\u001b[39;49mreshape(y_tr\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m],y_tr\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m)[:,\u001b[39m1\u001b[39;49m:] ,epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[es],batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m([x_val,y_val[:,:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]], y_val\u001b[39m.\u001b[39;49mreshape(y_val\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m],y_val\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m)[:,\u001b[39m1\u001b[39;49m:]))\n",
      "File \u001b[1;32md:\\Conda\\envs\\traffic-sign\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Conda\\envs\\traffic-sign\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Conda\\envs\\traffic-sign\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Conda\\envs\\traffic-sign\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Conda\\envs\\traffic-sign\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\Conda\\envs\\traffic-sign\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Conda\\envs\\traffic-sign\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Conda\\envs\\traffic-sign\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Conda\\envs\\traffic-sign\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fee59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61728d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('directml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "15982de9ef07d49ca26cdffe937ab9b96dac0fd348fa6aba314f0d9731c21e86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
