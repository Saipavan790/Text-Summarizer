{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c3c193",
   "metadata": {},
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb3b7110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66027a19",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e5a505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r\"C:\\Users\\Sai Pavan Vulasi\\Desktop\\text_dataset\\news_summary.csv\",encoding='iso-8859-1',usecols=['headlines','text'])\n",
    "df2 = pd.read_csv(r\"C:\\Users\\Sai Pavan Vulasi\\Desktop\\text_dataset\\news_summary_more.csv\",encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "413d6ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1  Malaika slams user who trolled her for 'divorc...   \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...   \n",
       "4  Hotel staff to get training to spot signs of s...   \n",
       "\n",
       "                                                text  \n",
       "0  The Administration of Union Territory Daman an...  \n",
       "1  Malaika Arora slammed an Instagram user who tr...  \n",
       "2  The Indira Gandhi Institute of Medical Science...  \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
       "4  Hotels in Maharashtra will train their staff t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44443515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4514, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b1b126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdfbacd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98401, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efd6c87",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3815a7",
   "metadata": {},
   "source": [
    "The aim of the preprocessing step is to reduce the\n",
    "dimensionality of the representation space, and it normally includes: (i) stop-word\n",
    "elimination – common words with no semantics and which do not aggregate relevant\n",
    "information to the task (e.g., “the”, “a”) are eliminated;; (ii) case folding: consists of\n",
    "converting all the characters to the same kind of letter case - either upper case or\n",
    "lower case; (iii) stemming: syntactically-similar words, such as plurals, verbal\n",
    "variations, etc. are considered similar; the purpose of this procedure is to obtain the\n",
    "stem or radix of each word, which emphasize its semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ae0028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1  Malaika slams user who trolled her for 'divorc...   \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...   \n",
       "4  Hotel staff to get training to spot signs of s...   \n",
       "\n",
       "                                                text  \n",
       "0  The Administration of Union Territory Daman an...  \n",
       "1  Malaika Arora slammed an Instagram user who tr...  \n",
       "2  The Indira Gandhi Institute of Medical Science...  \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
       "4  Hotels in Maharashtra will train their staff t...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate two dataframes to get total data\n",
    "df = pd.concat([df1,df2],axis=0,ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d71d0170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102915, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8324b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates and null values\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1c8949d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100266, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b4c656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size : 100266\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset size : {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13cf5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantext(text):\n",
    "    text = str(text)\n",
    "    text=text.split()\n",
    "    words=[]\n",
    "    for t in text:\n",
    "        if t.isalpha():\n",
    "            words.append(t)\n",
    "    text=\" \".join(words)\n",
    "    text=text.lower()\n",
    "    text=re.sub(r\"what's\",\"what is \",text)\n",
    "    text=re.sub(r\"it's\",\"it is \",text)\n",
    "    text=re.sub(r\"\\'ve\",\" have \",text)\n",
    "    text=re.sub(r\"i'm\",\"i am \",text)\n",
    "    text=re.sub(r\"\\'re\",\" are \",text)\n",
    "    text=re.sub(r\"n't\",\" not \",text)\n",
    "    text=re.sub(r\"\\'d\",\" would \",text)\n",
    "    text=re.sub(r\"\\'s\",\"s\",text)\n",
    "    text=re.sub(r\"\\'ll\",\" will \",text)\n",
    "    text=re.sub(r\"can't\",\" cannot \",text)\n",
    "    text=re.sub(r\" e g \",\" eg \",text)\n",
    "    text=re.sub(r\"e-mail\",\"email\",text)\n",
    "    text=re.sub(r\"9\\\\/11\",\" 911 \",text)\n",
    "    text=re.sub(r\" u.s\",\" american \",text)\n",
    "    text=re.sub(r\" u.n\",\" united nations \",text)\n",
    "    text=re.sub(r\"\\n\",\" \",text)\n",
    "    text=re.sub(r\":\",\" \",text)\n",
    "    text=re.sub(r\"-\",\" \",text)\n",
    "    text=re.sub(r\"\\_\",\" \",text)\n",
    "    text=re.sub(r\"\\d+\",\" \",text)\n",
    "    text=re.sub(r\"[$#@%&*!~?%{}()]\",\" \",text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d96dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: cleantext(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8f477a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daman diu revokes mandatory rakshabandhan in o...</td>\n",
       "      <td>the administration of union territory daman an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>malaika slams user who trolled her for rich</td>\n",
       "      <td>malaika arora slammed an instagram user who tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>now corrected to in form</td>\n",
       "      <td>the indira gandhi institute of medical science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaj aapne pakad let man dujana before being ki...</td>\n",
       "      <td>kashmir commander abu who was killed by securi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hotel staff to get training to spot signs of s...</td>\n",
       "      <td>hotels in maharashtra will train their staff t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  daman diu revokes mandatory rakshabandhan in o...   \n",
       "1        malaika slams user who trolled her for rich   \n",
       "2                           now corrected to in form   \n",
       "3  aaj aapne pakad let man dujana before being ki...   \n",
       "4  hotel staff to get training to spot signs of s...   \n",
       "\n",
       "                                                text  \n",
       "0  the administration of union territory daman an...  \n",
       "1  malaika arora slammed an instagram user who tr...  \n",
       "2  the indira gandhi institute of medical science...  \n",
       "3  kashmir commander abu who was killed by securi...  \n",
       "4  hotels in maharashtra will train their staff t...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "928db258",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['text'] = df['text']\n",
    "data['summary'] = df['headlines']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c8330",
   "metadata": {},
   "source": [
    "Remember to add the START and END special tokens at the beginning and end of the summary. Here, I have chosen sostok and eostok as START and END tokens. The beginning-of-sentence token serves as an instruction to the decoder to start decoding (it needs a very first state to predict what the next first token is). The end-of-sentence token is an instruction for the decoding algorithm to stop generating more tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177724a5",
   "metadata": {},
   "source": [
    "## Understanding distribution of sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c09d22",
   "metadata": {},
   "source": [
    "Here, we will analyze the length of the reviews and the summary to get an overall idea about the distribution of length of the text. This will help us fix the maximum length of the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "230b60d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999900265294317\n"
     ]
    }
   ],
   "source": [
    "text_count = 0\n",
    "for text in data['text']:\n",
    "    if len(text.split())<60:\n",
    "        text_count += 1\n",
    "print(text_count/len(data['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3de49ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999601061177269\n"
     ]
    }
   ],
   "source": [
    "summary_count = 0\n",
    "for summary in data['summary']:\n",
    "    if len(summary.split())<15:\n",
    "        summary_count+=1\n",
    "print(summary_count/len(data['summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3126cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# get number of words in text and summary\n",
    "\n",
    "for i in data['text']:\n",
    "    text_word_count.append(len(i.split()))\n",
    "    \n",
    "for i in data['summary']:\n",
    "    summary_word_count.append(len(str(i).split()))\n",
    "    \n",
    "length = pd.DataFrame()\n",
    "length['text'] = pd.Series(text_word_count)\n",
    "length['summary'] = pd.Series(summary_word_count)\n",
    "\n",
    "length.hist(bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74bd91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=60\n",
    "max_summary_len=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7de50c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text =np.array(data['text'])\n",
    "summary=np.array(data['summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(text)):\n",
    "    if(len(str(summary[i]).split())<=max_summary_len and len(text[i].split())<=max_text_len):\n",
    "        short_text.append(text[i])\n",
    "        short_summary.append(summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e5ed2",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8187055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96521441",
   "metadata": {},
   "source": [
    "## Tokenize: text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28735145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26da2c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 56.57998805546139\n",
      "Total Coverage of rare words: 1.1902033035582427\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77112b0",
   "metadata": {},
   "source": [
    "## Padding: pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a2cf8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08fc31c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26901"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e86bc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63703ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 55.5411057607817\n",
      "Total Coverage of rare words: 3.24588118639266\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c85184cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac81b365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12650"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "622e86af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m K\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[0;32m      4\u001b[0m K\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/CPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      6\u001b[0m     latent_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[0;32m      7\u001b[0m     embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "K.clear_session()\n",
    "with tf.device('/CPU:0'):\n",
    "    latent_dim = 300\n",
    "    embedding_dim=200\n",
    "\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "    #embedding layer\n",
    "    enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "    #encoder lstm 1\n",
    "    encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "    encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "    #encoder lstm 2\n",
    "    encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "    encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "    #encoder lstm 3\n",
    "    encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "    encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "    #embedding layer\n",
    "    dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "    dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "    decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "    #dense layer\n",
    "    decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model \n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a53b8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10cba72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d0a8bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'RMSprop/gradients/zeros_like_2' defined at (most recent call last):\n    File \"D:\\Conda\\envs\\venv\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\Conda\\envs\\venv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\Conda\\envs\\venv\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"D:\\Conda\\envs\\venv\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"D:\\Conda\\envs\\venv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Sai Pavan Vulasi\\AppData\\Local\\Temp\\ipykernel_12032\\2823602889.py\", line 1, in <cell line: 1>\n      history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'RMSprop/gradients/zeros_like_2'\nDetected at node 'RMSprop/gradients/zeros_like_2' defined at (most recent call last):\n    File \"D:\\Conda\\envs\\venv\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\Conda\\envs\\venv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\Conda\\envs\\venv\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"D:\\Conda\\envs\\venv\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"D:\\Conda\\envs\\venv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Sai Pavan Vulasi\\AppData\\Local\\Temp\\ipykernel_12032\\2823602889.py\", line 1, in <cell line: 1>\n      history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'RMSprop/gradients/zeros_like_2'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ZerosLike with the variant data type is not yet supported for pluggable devices in this version of TensorFlow.\n\t [[{{node RMSprop/gradients/zeros_like_2}}]]\n\t [[gradient_tape/model/lstm_3/while/model/lstm_3/while_grad/exit/_1659/_184]]\n  (1) INVALID_ARGUMENT:  ZerosLike with the variant data type is not yet supported for pluggable devices in this version of TensorFlow.\n\t [[{{node RMSprop/gradients/zeros_like_2}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_27080]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_tr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_tr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\Conda\\envs\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'RMSprop/gradients/zeros_like_2' defined at (most recent call last):\n    File \"D:\\Conda\\envs\\venv\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\Conda\\envs\\venv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\Conda\\envs\\venv\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"D:\\Conda\\envs\\venv\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"D:\\Conda\\envs\\venv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Sai Pavan Vulasi\\AppData\\Local\\Temp\\ipykernel_12032\\2823602889.py\", line 1, in <cell line: 1>\n      history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'RMSprop/gradients/zeros_like_2'\nDetected at node 'RMSprop/gradients/zeros_like_2' defined at (most recent call last):\n    File \"D:\\Conda\\envs\\venv\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"D:\\Conda\\envs\\venv\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"D:\\Conda\\envs\\venv\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"D:\\Conda\\envs\\venv\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"D:\\Conda\\envs\\venv\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Sai Pavan Vulasi\\AppData\\Local\\Temp\\ipykernel_12032\\2823602889.py\", line 1, in <cell line: 1>\n      history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"D:\\Conda\\envs\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'RMSprop/gradients/zeros_like_2'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  ZerosLike with the variant data type is not yet supported for pluggable devices in this version of TensorFlow.\n\t [[{{node RMSprop/gradients/zeros_like_2}}]]\n\t [[gradient_tape/model/lstm_3/while/model/lstm_3/while_grad/exit/_1659/_184]]\n  (1) INVALID_ARGUMENT:  ZerosLike with the variant data type is not yet supported for pluggable devices in this version of TensorFlow.\n\t [[{{node RMSprop/gradients/zeros_like_2}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_27080]"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fee59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu-python39",
   "language": "python",
   "name": "cpu-python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
